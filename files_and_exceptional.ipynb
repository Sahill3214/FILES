{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Q.1) SOLUTION BELOW"
      ],
      "metadata": {
        "id": "2Dx7lWZ7kufo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multithreading vs. Multiprocessing: Overview\n",
        "Multithreading: Involves running multiple threads within a single process. All threads share the same memory space, making it lightweight and efficient for certain tasks, but also introducing challenges like thread synchronization and race conditions.\n",
        "\n",
        "Multiprocessing: Involves running multiple processes, each with its own memory space. This is more resource-intensive than multithreading but can better take advantage of multi-core processors and handle processes that need isolation or significant CPU resources.\n",
        "\n",
        "Scenarios Where Multithreading is Preferable:\n",
        "I/O-bound Operations:\n",
        "\n",
        "Example: File reading/writing, database queries, network communication (e.g., web scraping or serving HTTP requests).\n",
        "Why: Threads can efficiently handle I/O-bound tasks because when one thread is waiting for an I/O operation to complete (such as fetching data from a disk or waiting for a network response), another thread can continue processing. This maximizes CPU utilization during I/O operations.\n",
        "Lightweight Tasks:\n",
        "\n",
        "Example: Simple background tasks like downloading images, logging data, or monitoring system status.\n",
        "Why: Threads are lightweight compared to processes. Since they share memory and resources, creating a large number of threads is more efficient than creating multiple processes. However, this is ideal when tasks don't need heavy computation but need to run concurrently.\n",
        "Shared Memory Requirement:\n",
        "\n",
        "Example: Tasks that need frequent communication or sharing of data (e.g., in simulation models or real-time monitoring systems).\n",
        "Why: Since all threads share the same memory space, they can easily access and modify shared data. This eliminates the overhead of inter-process communication (IPC) and allows threads to work closely together on shared tasks.\n",
        "Real-Time Applications (with proper management):\n",
        "\n",
        "Example: Real-time video streaming, audio processing, or UI updates.\n",
        "Why: Multithreading can help with managing responsiveness (e.g., user interface threads can run separately from processing tasks). However, it's crucial to avoid issues like thread contention that might cause delays.\n",
        "Low-Overhead Context Switching:\n",
        "\n",
        "Example: Small-scale applications that need to perform concurrent operations with minimal CPU usage, like GUI applications.\n",
        "Why: Thread context switching is generally cheaper than process context switching because threads share the same memory space and resources.\n",
        "Scenarios Where Multiprocessing is Preferable:\n",
        "CPU-bound Operations:\n",
        "\n",
        "Example: Heavy computation tasks like scientific simulations, image rendering, or data processing (e.g., machine learning model training, matrix operations).\n",
        "Why: Multiprocessing is better for CPU-bound tasks because each process runs independently and can be mapped to a separate core of a multi-core CPU. This avoids the Global Interpreter Lock (GIL) limitation in Python (for example), which prevents true parallel execution in multithreading.\n",
        "Task Isolation/Failure Recovery:\n",
        "\n",
        "Example: Independent tasks that require isolation, like running different service instances, processing data in parallel, or isolating failures (e.g., in microservices or batch jobs).\n",
        "Why: In multiprocessing, each process has its own memory and is isolated from others. If one process crashes, it won't affect others, unlike threads, which share memory and can introduce hard-to-debug issues due to race conditions.\n",
        "Parallelism on Multi-Core Systems:\n",
        "\n",
        "Example: Tasks like video transcoding, batch image processing, or rendering that require maximum CPU usage.\n",
        "Why: With multiprocessing, each process can run on a separate CPU core, leading to true parallel execution. This is particularly useful for tasks that need a lot of raw computation power.\n",
        "Avoiding GIL (Global Interpreter Lock) in Python:\n",
        "\n",
        "Example: Python programs that require CPU-intensive computation.\n",
        "Why: Python's GIL limits multithreaded programs from taking full advantage of multi-core CPUs for CPU-bound tasks. Using multiprocessing bypasses the GIL because each process runs in its own memory space with its own interpreter.\n",
        "Memory-Intensive Tasks:\n",
        "\n",
        "Example: Tasks that use large amounts of memory, like processing large datasets or performing memory-intensive simulations.\n",
        "Why: Processes in multiprocessing are independent, each with its own memory space. This prevents memory leaks or contention issues that may arise in multithreaded applications.\n",
        "Independent Workloads:\n",
        "\n",
        "Example: Running independent jobs like separate database queries, each needing its own context and resources.\n",
        "Why: Multiprocessing works well when tasks are independent and don’t require frequent communication between them. Each process can operate autonomously without interfering with the others.\n"
      ],
      "metadata": {
        "id": "wyaab948k1gF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.2)SOLUTION BELOW"
      ],
      "metadata": {
        "id": "ZePnyAO4lPCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A process pool is a collection of worker processes that are pre-initialized and ready to execute tasks in parallel. The concept of a process pool is often used to manage multiple processes efficiently, especially when dealing with tasks that require significant computational resources or when processes need to be run concurrently across multiple CPU cores.\n",
        "\n",
        "Process pools help manage multiple processes by abstracting the complexities of process creation, synchronization, and management. This makes it easier to scale workloads without overloading the system or creating unnecessary overhead for process management.\n",
        "\n",
        "Key Features of a Process Pool\n",
        "\n",
        "Pool of Worker Processes:\n",
        "\n",
        "A process pool consists of a fixed number of worker processes. These processes are created at the start and remain idle until they are assigned tasks. The number of worker processes can be adjusted based on the system's available resources and workload requirements.\n",
        "Task Assignment:\n",
        "\n",
        "When a task needs to be executed, it is submitted to the pool. The pool then assigns the task to one of the available worker processes. If no worker processes are available, the task waits in a queue until a process becomes free.\n",
        "Task Completion and Result Collection:\n",
        "\n",
        "Once a worker process completes a task, it can either be assigned another task from the queue or go back to being idle. The result of the task is typically collected through a callback mechanism or returned via a shared result collection (like a queue or list).\n",
        "Fixed or Dynamic Pool Size:\n",
        "\n",
        "The number of processes in the pool can be fixed, meaning the pool is created with a set number of worker processes, or it can be dynamic, meaning the pool can scale up or down based on workload or resource availability.\n",
        "Avoiding Overhead:\n",
        "\n",
        "By using a pool, the overhead of creating and destroying processes repeatedly is avoided. This is especially important in scenarios where tasks are frequently short-lived or where creating processes individually would be inefficient.\n",
        "How a Process Pool Helps in Managing Multiple Processes Efficiently\n",
        "Reduced Process Creation Overhead:\n",
        "\n",
        "Creating and destroying processes can be resource-intensive, especially if tasks are small and numerous. By using a process pool, the processes are created once and reused, which minimizes the overhead of spawning new processes for every task.\n",
        "Load Balancing:\n",
        "\n",
        "The process pool acts as a load balancer, distributing tasks to available worker processes in an efficient manner. If one process finishes a task, it becomes available for another task, ensuring that all worker processes are fully utilized without idle time.\n",
        "Efficient Resource Utilization:\n",
        "\n",
        "A process pool helps ensure that system resources, such as CPU cores and memory, are used efficiently. By limiting the number of processes to a set size (e.g., one per CPU core), the system avoids overloading, which could otherwise lead to performance degradation due to excessive context switching or resource contention.\n",
        "Simplified Task Management:\n",
        "\n",
        "Instead of manually managing individual processes and handling synchronization, a process pool abstracts these concerns. The pool handles the coordination of worker processes, task distribution, and result collection, allowing the developer to focus on the tasks themselves rather than process management.\n",
        "Error Handling:\n",
        "\n",
        "Process pools often provide built-in mechanisms to handle errors that occur in worker processes, such as retries, logging, or raising exceptions to the main process. This simplifies error handling and improves the robustness of concurrent processing.\n",
        "Scalability:\n",
        "\n",
        "A process pool can be easily scaled to handle a large number of tasks. By simply adjusting the number of worker processes, the pool can scale according to the available hardware (e.g., CPU cores) or workload size. Dynamic pools can even scale down during periods of low demand, conserving resources.\n",
        "Improved Parallelism:\n",
        "\n",
        "With a pool of processes, tasks can be executed in parallel on multiple CPU cores, taking full advantage of multi-core systems. This is particularly beneficial for CPU-bound tasks, where parallelism can significantly speed up processing.\n",
        "Example: Using a Process Pool in Python with multiprocessing.\n",
        "\n",
        "\n",
        "Pool\n",
        "In Python, the multiprocessing module provides the Pool class, which simplifies the management of a process pool. Here's a basic example to demonstrate how it works:"
      ],
      "metadata": {
        "id": "_pE1xO47lR59"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pdo6HGeUkpA6",
        "outputId": "cf69fa6f-145b-4c95-abf9-83df42f32872"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ],
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "def square(x):\n",
        "    return x * x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # Create a pool of 4 worker processes\n",
        "    with Pool(4) as pool:\n",
        "        # Map a list of numbers to the square function using the pool\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "    print(results)  # Output: [1, 4, 9, 16, 25]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.3) SOLUTION BELOW"
      ],
      "metadata": {
        "id": "wDABJrOnly4O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multiprocessing is a parallel computing technique that allows a program to execute multiple processes concurrently, each running in its own memory space. It enables the program to take advantage of multiple CPU cores, allowing for true parallel execution of tasks. Unlike multithreading, where threads share the same memory space, multiprocessing runs separate processes with their own independent memory, making it well-suited for CPU-bound tasks that require significant computational power.\n",
        "\n",
        "In Python, the multiprocessing module provides an easy way to create and manage processes. It allows Python programs to bypass the Global Interpreter Lock (GIL), which can be a limiting factor for multithreaded programs in Python.\n",
        "\n",
        "Key Concepts of Multiprocessing\n",
        "Process:\n",
        "\n",
        "A process is an independent execution unit that has its own memory space. In the context of Python, the multiprocessing module allows you to spawn separate processes that run in parallel.\n",
        "Task Parallelism:\n",
        "\n",
        "Multiprocessing works well for parallelizing tasks that can be executed independently. The task is divided into smaller chunks, and each chunk is processed in a separate process.\n",
        "CPU-bound vs. I/O-bound:\n",
        "\n",
        "Multiprocessing is particularly useful for CPU-bound tasks (tasks that require significant computation), such as mathematical computations, data processing, or machine learning tasks. It is less useful for I/O-bound tasks (such as file I/O, network requests), which are typically better handled by multithreading or asynchronous programming.\n",
        "Independent Memory:\n",
        "\n",
        "Each process in a multiprocessing system has its own memory space. This isolation of memory makes multiprocessing more robust because one process cannot corrupt the memory of another. However, it also makes inter-process communication (IPC) more complex and slower than in multithreading.\n",
        "\n",
        "\n",
        "Why Use Multiprocessing in Python?\n",
        "\n",
        "1. Bypassing the Global Interpreter Lock (GIL)\n",
        "The Global Interpreter Lock (GIL) is a mutex (lock) in the CPython interpreter that allows only one thread to execute Python bytecode at a time, even in multi-core systems. This means that Python programs using threads for CPU-bound tasks are often unable to achieve true parallelism on multi-core systems.\n",
        "Multiprocessing solves this problem because each process runs independently and has its own Python interpreter and memory space. This allows Python to utilize multiple CPU cores fully for CPU-bound tasks.\n",
        "2. True Parallelism for CPU-bound Tasks\n",
        "CPU-bound tasks are those that require heavy computation, such as:\n",
        "Image processing (e.g., resizing, filtering)\n",
        "Data analysis (e.g., large dataset manipulation)\n",
        "Scientific simulations (e.g., simulations involving large amounts of numerical computation)\n",
        "Multiprocessing allows such tasks to be split across multiple processes, enabling true parallelism where each process can run on a separate CPU core. This results in significant performance improvements for CPU-intensive programs.\n",
        "3. Improved Performance\n",
        "By taking advantage of multiple CPU cores, multiprocessing can speed up tasks that involve large amounts of data or complex calculations. For example, a large dataset can be split into chunks, and each chunk can be processed in parallel across different CPU cores. This parallelism can lead to faster overall execution compared to sequential processing.\n",
        "4. Fault Isolation\n",
        "Processes in multiprocessing are isolated from each other, meaning that if one process crashes or encounters an error, it doesn't affect the others. This makes multiprocessing more robust than multithreading for certain applications where fault tolerance is important.\n",
        "5. Memory Efficiency for Certain Workloads\n",
        "Since each process in a multiprocessing system has its own memory, it can be more efficient for certain workloads where tasks need isolated memory spaces. For example, processes that work on separate parts of a large dataset can avoid memory contention issues and data corruption that might occur in multithreaded environments.\n",
        "6. Simplified Parallel Programming\n",
        "While managing multiple processes might seem more complex than threads due to the need for inter-process communication (IPC), multiprocessing abstracts away a lot of the complexity by providing high-level constructs like Pool, Queue, and Pipe. These tools make it easier to manage the parallel execution of tasks without having to manually create and synchronize threads.\n",
        "\n",
        "\n",
        "Example of Using Multiprocessing in Python\n",
        "\n",
        "\n",
        "Here's a simple example to demonstrate the use of multiprocessing in Python:"
      ],
      "metadata": {
        "id": "8R0nD-pJmXjp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def square(number):\n",
        "    return number * number\n",
        "\n",
        "def main():\n",
        "    # Create a pool of 4 processes\n",
        "    with multiprocessing.Pool(4) as pool:\n",
        "        # Map the `square` function to a list of numbers\n",
        "        results = pool.map(square, [1, 2, 3, 4, 5])\n",
        "\n",
        "    print(results)  # Output: [1, 4, 9, 16, 25]\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41HcZeXKmUQf",
        "outputId": "f62b449b-12a7-45f5-f5ae-65c622311174"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 4, 9, 16, 25]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.4) SOLUTION BELOW"
      ],
      "metadata": {
        "id": "ZJgZhlLgmjy5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "import time\n",
        "\n",
        "# Shared list to be modified by both threads\n",
        "shared_list = []\n",
        "\n",
        "# Lock to prevent race conditions\n",
        "list_lock = threading.Lock()\n",
        "\n",
        "# Function to add numbers to the list\n",
        "def add_numbers():\n",
        "    for i in range(10):\n",
        "        time.sleep(0.1)  # Simulate work (e.g., calculation or I/O)\n",
        "        with list_lock:  # Acquire lock before modifying the shared list\n",
        "            shared_list.append(i)\n",
        "            print(f\"Added: {i}\")\n",
        "\n",
        "# Function to remove numbers from the list\n",
        "def remove_numbers():\n",
        "    while True:\n",
        "        time.sleep(0.2)  # Simulate work (e.g., calculation or I/O)\n",
        "        with list_lock:  # Acquire lock before modifying the shared list\n",
        "            if shared_list:  # Check if the list is not empty\n",
        "                removed = shared_list.pop(0)\n",
        "                print(f\"Removed: {removed}\")\n",
        "            else:\n",
        "                print(\"List is empty, waiting for numbers to add.\")\n",
        "                break  # Exit if the list is empty\n",
        "\n",
        "# Main function to set up threads\n",
        "def main():\n",
        "    # Create threads for adding and removing numbers\n",
        "    add_thread = threading.Thread(target=add_numbers)\n",
        "    remove_thread = threading.Thread(target=remove_numbers)\n",
        "\n",
        "    # Start both threads\n",
        "    add_thread.start()\n",
        "    remove_thread.start()\n",
        "\n",
        "    # Wait for both threads to finish\n",
        "    add_thread.join()\n",
        "    remove_thread.join()\n",
        "\n",
        "# Run the program\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-juun0NOmzWY",
        "outputId": "240998dc-fa26-4d7a-c0bb-cd519d9ca625"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Added: 0\n",
            "Removed: 0\n",
            "Added: 1\n",
            "Added: 2\n",
            "Removed: 1\n",
            "Added: 3\n",
            "Added: 4\n",
            "Removed: 2\n",
            "Added: 5\n",
            "Added: 6\n",
            "Removed: 3\n",
            "Added: 7\n",
            "Added: 8\n",
            "Removed: 4\n",
            "Added: 9\n",
            "Removed: 5\n",
            "Removed: 6\n",
            "Removed: 7\n",
            "Removed: 8\n",
            "Removed: 9\n",
            "List is empty, waiting for numbers to add.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.5) SOLUTION BELOW"
      ],
      "metadata": {
        "id": "4Kh16EjfmmVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Python, when working with multithreading and multiprocessing, it’s important to safely share data between threads or processes to avoid race conditions, data corruption, or other concurrency issues. Python provides various tools and methods for safely sharing data between threads and processes, each suited for specific scenarios."
      ],
      "metadata": {
        "id": "2QrOjZu5nDZq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.6) SOLUTION BELOW"
      ],
      "metadata": {
        "id": "tGeNi1DwnEur"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Isolation of Errors:\n",
        "\n",
        "In concurrent programs, errors in one thread or process should not necessarily affect the entire program. For instance, a failure in one worker thread should not bring down the whole application.\n",
        "\n",
        "If exceptions are not handled properly, they may propagate unnoticed, causing partial or total failure of the program, and potentially leaving shared resources in an inconsistent state.\n",
        "Graceful Termination:\n",
        "\n",
        "Without exception handling, a program may abruptly crash when an error occurs in one of its concurrent tasks. Proper handling ensures that threads and processes can either recover or terminate gracefully, possibly allowing other tasks to continue.\n",
        "\n",
        "Deadlocks and Resource Leaks:\n",
        "\n",
        "When exceptions are not handled in concurrent systems, resources like locks, file handles, or memory may not be released properly, leading to deadlocks or resource leaks. Proper exception handling helps ensure that resources are cleaned up appropriately, even in the event of an error.\n",
        "Debugging Complexity:\n",
        "\n",
        "Concurrent programs are harder to debug because multiple threads or processes can fail in different ways and order. If exceptions are not handled in a clear, systematic way, it can be very difficult to pinpoint the source of the error and resolve it.\n",
        "\n",
        "Ensuring Robustness:\n",
        "\n",
        "Handling exceptions allows you to recover from temporary issues (such as network timeouts or file access issues) and take corrective actions, such as retrying operations or logging the error for further investigation.\n",
        "Techniques for Handling Exceptions in Concurrent Programs\n",
        "\n",
        "1. Try-Except Blocks (Standard Exception Handling)\n",
        "In both multithreading and multiprocessing, the basic Python exception handling mechanism (try-except) can be used within individual tasks to catch and handle exceptions locally. This is particularly useful to ensure that one failure doesn’t propagate and bring down the entire program.\n",
        "\n",
        "Example (Threaded Task with Exception Handling):\n",
        "\n"
      ],
      "metadata": {
        "id": "wHZPBhadnHlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        # Simulating a task that may raise an exception\n",
        "        result = 10 / 0  # Division by zero\n",
        "    except ZeroDivisionError as e:\n",
        "        print(f\"Error in thread: {e}\")\n",
        "\n",
        "# Create and start the thread\n",
        "t = threading.Thread(target=task)\n",
        "t.start()\n",
        "t.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jTdOcIaSmibb",
        "outputId": "400b960f-12b0-49f2-e21a-5fd76904f671"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error in thread: division by zero\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Handling Exceptions in ThreadPoolExecutor (Threading)\n",
        "In thread pools, exceptions raised in worker threads can be captured by the Future object associated with the task. The Future object has an exception() method that allows you to retrieve any exceptions raised during the execution of the task.\n",
        "\n",
        "Example (Handling Exceptions in ThreadPoolExecutor):"
      ],
      "metadata": {
        "id": "uEA5Ee13nhcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from concurrent.futures import ThreadPoolExecutor\n",
        "\n",
        "def task(n):\n",
        "    if n == 0:\n",
        "        raise ValueError(\"n cannot be zero\")\n",
        "    return 10 / n\n",
        "\n",
        "with ThreadPoolExecutor(max_workers=2) as executor:\n",
        "    futures = [executor.submit(task, i) for i in [1, 0, 2]]\n",
        "\n",
        "    for future in futures:\n",
        "        try:\n",
        "            result = future.result()  # Get the result, raises exception if any\n",
        "            print(result)\n",
        "        except Exception as e:\n",
        "            print(f\"Task failed with exception: {e}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vw_gIyfYngWx",
        "outputId": "e64c18f9-38a9-4fa9-b374-d3b01564c5ea"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.0\n",
            "Task failed with exception: n cannot be zero\n",
            "5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Handling Exceptions in Process Pools (Multiprocessing)\n",
        "When using multiprocessing, exceptions in child processes do not propagate to the parent process by default. However, you can catch exceptions by using the multiprocessing.Pool class, which provides a map or apply function that returns results and raises exceptions from worker processes.\n",
        "\n",
        "Example (Handling Exceptions in Pool):"
      ],
      "metadata": {
        "id": "uXHvRarnnnWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "\n",
        "def task(n):\n",
        "    if n == 0:\n",
        "        raise ValueError(\"n cannot be zero\")\n",
        "    return 10 / n\n",
        "\n",
        "def worker(n):\n",
        "    try:\n",
        "        return task(n)\n",
        "    except Exception as e:\n",
        "        return f\"Error in process: {e}\"\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with multiprocessing.Pool(3) as pool:\n",
        "        results = pool.map(worker, [1, 0, 2])\n",
        "        print(results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmbgwL9bnmhB",
        "outputId": "7c356582-ae37-4057-ecaa-722791c3fc9c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10.0, 'Error in process: n cannot be zero', 5.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using try-finally for Resource Cleanup\n",
        "In concurrent programs, especially when dealing with shared resources (like files, network connections, or locks), it's essential to ensure that resources are cleaned up correctly, even when an exception occurs.\n",
        "\n",
        "try-finally can be used to ensure that resources are released or cleaned up, regardless of whether an exception occurred.\n",
        "Example (Using try-finally to Release Resources):"
      ],
      "metadata": {
        "id": "84Jf7L-anvGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import threading\n",
        "\n",
        "lock = threading.Lock()\n",
        "\n",
        "def task():\n",
        "    try:\n",
        "        lock.acquire()\n",
        "        # Simulate task\n",
        "        raise ValueError(\"Something went wrong!\")\n",
        "    finally:\n",
        "        lock.release()  # Ensure the lock is always released\n",
        "\n",
        "# Create and start the thread\n",
        "t = threading.Thread(target=task)\n",
        "t.start()\n",
        "t.join()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-CA2I5bynr7C",
        "outputId": "02f3e7b4-7fff-4161-e0c0-78b48a8500b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-22 (task):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-8-3db3a5284ca7>\", line 9, in task\n",
            "ValueError: Something went wrong!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.7) SOLUTION BELOW"
      ],
      "metadata": {
        "id": "bVCRFzNdnzJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To create a program that calculates the factorial of numbers from 1 to 10 concurrently using ThreadPoolExecutor from the concurrent.futures module, you can follow these steps:\n",
        "\n",
        "Steps:\n",
        "Define a function to calculate the factorial of a number.\n",
        "Use ThreadPoolExecutor to manage the concurrent execution of factorial calculations.\n",
        "Submit tasks to the thread pool for each number from 1 to 10.\n",
        "Gather the results and print them once the calculations are complete."
      ],
      "metadata": {
        "id": "27UdcjcPn1hj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import concurrent.futures\n",
        "import math\n",
        "\n",
        "# Function to calculate the factorial of a number\n",
        "def calculate_factorial(n):\n",
        "    return math.factorial(n)\n",
        "\n",
        "def main():\n",
        "    # Create a ThreadPoolExecutor with a specified number of threads (e.g., 4 threads)\n",
        "    with concurrent.futures.ThreadPoolExecutor(max_workers=4) as executor:\n",
        "        # Submit the factorial calculation tasks for numbers 1 to 10\n",
        "        futures = {executor.submit(calculate_factorial, i): i for i in range(1, 11)}\n",
        "\n",
        "        # Wait for all tasks to complete and get the results\n",
        "        for future in concurrent.futures.as_completed(futures):\n",
        "            num = futures[future]  # Retrieve the number for which the factorial was calculated\n",
        "            try:\n",
        "                result = future.result()  # Get the result of the factorial calculation\n",
        "                print(f\"Factorial of {num} is {result}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error calculating factorial for {num}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bN0T2Qqnxe5",
        "outputId": "12962eb2-83ed-4e5b-8bf8-a02d8ad01dbe"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Factorial of 2 is 2\n",
            "Factorial of 4 is 24\n",
            "Factorial of 3 is 6\n",
            "Factorial of 1 is 1\n",
            "Factorial of 7 is 5040\n",
            "Factorial of 9 is 362880\n",
            "Factorial of 10 is 3628800\n",
            "Factorial of 8 is 40320\n",
            "Factorial of 6 is 720\n",
            "Factorial of 5 is 120\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation:\n",
        "calculate_factorial(n):\n",
        "\n",
        "This function simply calculates the factorial of a number using Python's built-in math.factorial() function.\n",
        "ThreadPoolExecutor(max_workers=4):\n",
        "\n",
        "The ThreadPoolExecutor manages a pool of threads. We specify max_workers=4, meaning the pool can run up to 4 threads concurrently. You can adjust this number depending on how many threads you want to run simultaneously.\n",
        "Submitting tasks to the thread pool:\n",
        "\n",
        "The executor.submit(calculate_factorial, i) call submits the task of calculating the factorial for each number i from 1 to 10.\n",
        "The submit method returns a Future object that will eventually contain the result of the computation.\n",
        "futures dictionary:\n",
        "\n",
        "We maintain a dictionary of futures where the key is the Future object returned by submit, and the value is the number for which the factorial is being computed. This helps us track which number the result corresponds to.\n",
        "concurrent.futures.as_completed(futures):\n",
        "\n",
        "This function yields each Future object as it completes. It ensures that results are processed as soon as they become available (i.e., asynchronously).\n",
        "Exception Handling:\n",
        "\n",
        "If any task raises an exception, it is caught using try-except around future.result() to ensure the program doesn't crash and provides feedback for any issues that occur."
      ],
      "metadata": {
        "id": "g1tDTycpoD06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q.8) SOLUTION BELOW"
      ],
      "metadata": {
        "id": "G3HwBhD9oIk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "import time\n",
        "\n",
        "# Function to compute the square of a number\n",
        "def compute_square(n):\n",
        "    return n * n\n",
        "\n",
        "# Function to measure time and compute squares with different pool sizes\n",
        "def compute_squares_with_pool(pool_size):\n",
        "    # Start the timer\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create a Pool with the specified number of processes\n",
        "    with multiprocessing.Pool(pool_size) as pool:\n",
        "        # Compute the squares for numbers from 1 to 10 in parallel\n",
        "        results = pool.map(compute_square, range(1, 11))\n",
        "\n",
        "    # End the timer\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Calculate the time taken\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    # Print the results and time taken\n",
        "    print(f\"Pool size: {pool_size} -> Results: {results}\")\n",
        "    print(f\"Time taken: {time_taken:.6f} seconds\\n\")\n",
        "\n",
        "def main():\n",
        "    # Define different pool sizes to test\n",
        "    pool_sizes = [2, 4, 8]\n",
        "\n",
        "    # Test each pool size and measure time\n",
        "    for pool_size in pool_sizes:\n",
        "        compute_squares_with_pool(pool_size)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONXhs0sroCWy",
        "outputId": "529be211-54ec-4b23-e7ec-28f75ec0ad99"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pool size: 2 -> Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.027669 seconds\n",
            "\n",
            "Pool size: 4 -> Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.047766 seconds\n",
            "\n",
            "Pool size: 8 -> Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
            "Time taken: 0.089059 seconds\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nNyup2QtoS8p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}